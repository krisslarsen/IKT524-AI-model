{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "647fad49",
   "metadata": {},
   "source": [
    "\n",
    "# Nutrition5k × YOLO11 — Classification Training (Calorie/Macro buckets)\n",
    "\n",
    "**Nutrition5k** is primarily a *regression* dataset (predict calories/macros), not a labeled classification set.  \n",
    "To reuse the same YOLO‑classification workflow you used for Food‑11/101, this notebook derives **coarse labels** from nutrition metadata:\n",
    "\n",
    "- **`primary_macro`** (default): `carb`, `protein`, or `fat` depending on which macronutrient (g) is highest.\n",
    "- **`calorie_bin`** (optional): 5 quantile bins based on total calories per dish.\n",
    "\n",
    "It then builds `train/`, `val/`, `test/` splits and trains **`yolo11n-cls.pt`**.\n",
    "\n",
    "> If your Kaggle ref stores images as **bytes inside tables**, this notebook can *materialize* RGB images to JPEGs.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "e77719c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T08:38:23.711200Z",
     "start_time": "2025-12-10T08:38:23.703300Z"
    }
   },
   "source": [
    "\n",
    "# --- 1) Paths & knobs ----------------------------------------------------------\n",
    "import os, pathlib, random, shutil, sys, re, ast, base64, io\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "# Root where you copied the Kaggle cache\n",
    "DATASET_ROOT = \"/home/kristoffel/datasets/dataset-01-Nutrition5k\"   # ← edit if needed\n",
    "MODEL_DIR    = \"/home/kristoffel/models\"\n",
    "\n",
    "# Where to place materialized RGB images (if starting from bytes/tables)\n",
    "RGB_DIR = os.path.join(DATASET_ROOT, \"images_rgb\")  # we'll create <dish_id> subfolders\n",
    "\n",
    "# Output splits for YOLO classification\n",
    "TRAIN_DIR = os.path.join(DATASET_ROOT, \"train\")\n",
    "VAL_DIR   = os.path.join(DATASET_ROOT, \"val\")\n",
    "TEST_DIR  = os.path.join(DATASET_ROOT, \"test\")\n",
    "\n",
    "# Labeling strategy ('primary_macro' or 'calorie_bin')\n",
    "LABEL_STRATEGY = \"primary_macro\"   # ← edit me\n",
    "\n",
    "# Split ratios\n",
    "VAL_RATIO  = 0.10\n",
    "TEST_RATIO = 0.10\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "assert os.path.isdir(DATASET_ROOT), f\"Missing dataset root: {DATASET_ROOT}\"\n",
    "print(\"Paths OK. Root:\", DATASET_ROOT)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths OK. Root: /home/kristoffel/datasets/dataset-01-Nutrition5k\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "e8e0be65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T08:38:27.725803Z",
     "start_time": "2025-12-10T08:38:27.182678Z"
    }
   },
   "source": [
    "\n",
    "# --- 2) Locate source tables and/or images ------------------------------------\n",
    "# Nutrition5k Kaggle variants differ. We'll try to find:\n",
    "#  - a dish-level nutrition table (for calories/macros) -> used to derive labels\n",
    "#  - an images table containing byte-encoded RGB (if no JPEGs are present)\n",
    "#\n",
    "# We also support a mirror which already has JPEGs in directories.\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "def find_first_file(root: str, patterns):\n",
    "    for pat in patterns:\n",
    "        hits = sorted(glob(os.path.join(root, \"**\", pat), recursive=True))\n",
    "        if hits:\n",
    "            return hits[0]\n",
    "    return None\n",
    "\n",
    "# Candidate files for nutrition (dish-level)\n",
    "NUTR_PATTERNS = [\n",
    "    \"*dish_nutrition.*\", \"*dish*nutrition.*\", \"*nutrition*.csv\", \"*nutrition*.parquet\", \"*nutrition*.feather\", \"*nutrition*.pkl\"\n",
    "]\n",
    "\n",
    "# Candidates for image tables\n",
    "IMG_PATTERNS = [\n",
    "    \"*dish_images.*\", \"*images_table.*\", \"*images*.parquet\", \"*images*.feather\", \"*images*.pkl\", \"*images*.csv\"\n",
    "]\n",
    "\n",
    "# Already-materialized JPEGs (side-angle mirror or preprocessed)\n",
    "JPEG_ROOT = None\n",
    "for cand in [os.path.join(DATASET_ROOT, \"images\"), os.path.join(DATASET_ROOT, \"images_rgb\"), DATASET_ROOT]:\n",
    "    if os.path.isdir(cand) and any(Path(cand).glob(\"**/*.jpg\")):\n",
    "        JPEG_ROOT = cand\n",
    "        break\n",
    "\n",
    "nutr_file = find_first_file(DATASET_ROOT, NUTR_PATTERNS)\n",
    "img_table = find_first_file(DATASET_ROOT, IMG_PATTERNS)\n",
    "\n",
    "print(\"nutrition file:\", nutr_file)\n",
    "print(\"image table   :\", img_table)\n",
    "print(\"jpeg root     :\", JPEG_ROOT)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nutrition file: None\n",
      "image table   : /home/kristoffel/datasets/dataset-01-Nutrition5k/dish_images.pkl\n",
      "jpeg root     : None\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "1f2c45d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T08:39:06.708210Z",
     "start_time": "2025-12-10T08:39:06.678379Z"
    }
   },
   "source": [
    "\n",
    "# --- 3) Load nutrition and derive labels --------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "assert nutr_file, \"Could not find a nutrition table. Please point NUTR_PATTERNS to your dish-level nutrition file.\"\n",
    "\n",
    "def read_any_table(path: str) -> pd.DataFrame:\n",
    "    low = path.lower()\n",
    "    if low.endswith(\".csv\"):\n",
    "        return pd.read_csv(path)\n",
    "    if low.endswith(\".parquet\"):\n",
    "        return pd.read_parquet(path)\n",
    "    if low.endswith(\".feather\"):\n",
    "        import pyarrow  # noqa\n",
    "        return pd.read_feather(path)\n",
    "    if low.endswith((\".pkl\", \".pickle\")):\n",
    "        import pickle\n",
    "        return pd.read_pickle(path)\n",
    "    raise ValueError(f\"Unsupported table format: {path}\")\n",
    "\n",
    "df_nutr = read_any_table(nutr_file)\n",
    "cols = {c.strip(): c for c in df_nutr.columns}\n",
    "norm = {k.lower().replace(\" \", \"\").replace(\"(\", \"\").replace(\")\", \"\"): v for k,v in cols.items()}\n",
    "\n",
    "def pick(name_alts):\n",
    "    for a in name_alts:\n",
    "        key = a.lower().replace(\" \", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        if key in norm:\n",
    "            return norm[key]\n",
    "    return None\n",
    "\n",
    "# Try to identify key columns (robust to different namings)\n",
    "dish_col = pick([\"dish_id\",\"id\",\"sample_id\",\"plate_id\",\"dish\"])\n",
    "cal_col  = pick([\"calories\",\"kcal\",\"energykcal\",\"energy_kcal\"])\n",
    "pro_col  = pick([\"protein\",\"protein_g\",\"proteing\"])\n",
    "fat_col  = pick([\"fat\",\"fat_g\",\"fatg\",\"totalfat_g\",\"totalfat\"])\n",
    "carb_col = pick([\"carbohydrate\",\"carbohydrates\",\"carbs\",\"carb_g\",\"carbohydrates_g\",\"carbohydrateg\"])\n",
    "\n",
    "for need, col in [(\"dish id\", dish_col), (\"calories\", cal_col), (\"protein\", pro_col), (\"fat\", fat_col), (\"carbohydrate\", carb_col)]:\n",
    "    print(f\"{need:12s}:\", col)\n",
    "\n",
    "assert dish_col is not None, \"Could not find a dish ID column in the nutrition table.\"\n",
    "\n",
    "# Keep rows that have nutrition values (when available)\n",
    "df = df_nutr.copy()\n",
    "df = df.dropna(subset=[dish_col])\n",
    "\n",
    "# Build labels\n",
    "if LABEL_STRATEGY == \"primary_macro\" and all(x is not None for x in [pro_col, fat_col, carb_col]):\n",
    "    def primary_macro(r):\n",
    "        vals = [(r[pro_col], \"protein\"), (r[fat_col], \"fat\"), (r[carb_col], \"carb\")]\n",
    "        # Handle missing / NaN\n",
    "        vals = [(0 if pd.isna(v) else float(v), name) for v,name in vals]\n",
    "        return max(vals)[1]\n",
    "    df[\"label\"] = df.apply(primary_macro, axis=1)\n",
    "    class_names = [\"carb\",\"protein\",\"fat\"]\n",
    "elif LABEL_STRATEGY == \"calorie_bin\" and cal_col is not None:\n",
    "    # 5 quantile bins for calories\n",
    "    df = df.dropna(subset=[cal_col])\n",
    "    df[\"label\"] = pd.qcut(df[cal_col].astype(float), q=5, duplicates=\"drop\").astype(str)\n",
    "    class_names = sorted(df[\"label\"].unique().tolist())\n",
    "else:\n",
    "    raise RuntimeError(\"Chosen LABEL_STRATEGY is not supported by available columns. \"\n",
    "                       \"Try LABEL_STRATEGY='primary_macro' or ensure calories/macros exist.\")\n",
    "\n",
    "# Keep only dish_id, label\n",
    "df_lbl = df[[dish_col, \"label\"]].drop_duplicates().reset_index(drop=True)\n",
    "df_lbl.columns = [\"dish_id\",\"label\"]\n",
    "print(\"Label distribution:\")\n",
    "print(df_lbl[\"label\"].value_counts())\n"
   ],
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Could not find a nutrition table. Please point NUTR_PATTERNS to your dish-level nutrition file.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m nutr_file, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not find a nutrition table. Please point NUTR_PATTERNS to your dish-level nutrition file.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread_any_table\u001B[39m(path: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame:\n\u001B[1;32m      8\u001B[0m     low \u001B[38;5;241m=\u001B[39m path\u001B[38;5;241m.\u001B[39mlower()\n",
      "\u001B[0;31mAssertionError\u001B[0m: Could not find a nutrition table. Please point NUTR_PATTERNS to your dish-level nutrition file."
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb4513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 4) Materialize JPEGs if needed -------------------------------------------\n",
    "# Many Nutrition5k mirrors store images as bytes in a table.\n",
    "# We'll attempt to decode to JPEGs in images_rgb/<dish_id>/img_<idx>.jpg\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast, base64, re\n",
    "\n",
    "if JPEG_ROOT is None:\n",
    "    assert img_table, \"No JPEGs found and no image table located. Provide an images table or use a mirror with JPEGs.\"\n",
    "    df_img = read_any_table(img_table)\n",
    "    print(\"Images table columns:\", df_img.columns.tolist())\n",
    "\n",
    "    # Try to find dish id column and an RGB bytes column\n",
    "    cols = {c.strip(): c for c in df_img.columns}\n",
    "    norm = {k.lower().replace(\" \", \"\").replace(\"(\", \"\").replace(\")\", \"\"): v for k,v in cols.items()}\n",
    "\n",
    "    dish_img_col = None\n",
    "    for a in [\"dish_id\",\"id\",\"sample_id\",\"plate_id\",\"dish\"]:\n",
    "        k = a.lower().replace(\" \", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        if k in norm:\n",
    "            dish_img_col = norm[k]; break\n",
    "    assert dish_img_col is not None, \"Could not find a dish id column in images table.\"\n",
    "\n",
    "    rgb_col = None\n",
    "    for a in [\"rgb\",\"rgb_bytes\",\"image\",\"image_bytes\",\"rgbimage\",\"rgbimagebytes\"]:\n",
    "        k = a.lower().replace(\" \", \"\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        if k in norm:\n",
    "            rgb_col = norm[k]; break\n",
    "    assert rgb_col is not None, \"Could not find an RGB image bytes column.\"\n",
    "\n",
    "    # Make output root\n",
    "    out_root = Path(RGB_DIR)\n",
    "    out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def decode_to_bytes(x):\n",
    "        # Handle: bytes, base64 str, python bytes literal in string\n",
    "        if isinstance(x, (bytes, bytearray)):\n",
    "            return bytes(x)\n",
    "        if isinstance(x, memoryview):\n",
    "            return x.tobytes()\n",
    "        if isinstance(x, str):\n",
    "            s = x.strip()\n",
    "            # Python bytes literal\n",
    "            if (s.startswith(\"b'\") or s.startswith('b\"')) and s.endswith((\"'\",'\"')):\n",
    "                return ast.literal_eval(s)\n",
    "            # Base64?\n",
    "            try:\n",
    "                return base64.b64decode(s, validate=True)\n",
    "            except Exception:\n",
    "                pass\n",
    "        raise ValueError(\"Unsupported RGB encoding type\")\n",
    "\n",
    "    count, skipped = 0, 0\n",
    "    for ridx, row in df_img.iterrows():\n",
    "        dish_id = str(row[dish_img_col])\n",
    "        try:\n",
    "            rgb_bytes = decode_to_bytes(row[rgb_col])\n",
    "            img = Image.open(BytesIO(rgb_bytes)).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        dish_dir = out_root / dish_id\n",
    "        dish_dir.mkdir(exist_ok=True, parents=True)\n",
    "        # sequential filename\n",
    "        out_path = dish_dir / f\"img_{len(list(dish_dir.glob('img_*.jpg'))):05d}.jpg\"\n",
    "        img.save(out_path, format=\"JPEG\", quality=90)\n",
    "        count += 1\n",
    "        if count % 500 == 0:\n",
    "            print(\"saved\", count, \"images...\")\n",
    "    print(f\"Saved {count} images to {out_root} ({skipped} skipped).\")\n",
    "    JPEG_ROOT = str(out_root)\n",
    "else:\n",
    "    print(\"Found JPEGs under:\", JPEG_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06092261",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 5) Pair images to labels and build splits --------------------------------\n",
    "import os, glob, random, shutil\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "# Build map dish_id -> list of image paths\n",
    "dish_to_paths = defaultdict(list)\n",
    "for p in Path(JPEG_ROOT).glob(\"**/*.jpg\"):\n",
    "    # expect path .../<dish_id>/filename.jpg\n",
    "    dish_id = p.parent.name\n",
    "    dish_to_paths[dish_id].append(str(p))\n",
    "\n",
    "# Join with labels\n",
    "label_map = dict(df_lbl.values)  # dish_id -> label\n",
    "pairs = [(dish, label_map.get(dish, None), imgs) for dish, imgs in dish_to_paths.items()]\n",
    "pairs = [(d,l,imgs) for (d,l,imgs) in pairs if l is not None and len(imgs)>0]\n",
    "\n",
    "print(\"Dishes with labels & images:\", len(pairs))\n",
    "\n",
    "# Split by dish (to avoid leakage across splits)\n",
    "by_label = defaultdict(list)\n",
    "for dish, label, imgs in pairs:\n",
    "    by_label[label].append((dish, imgs))\n",
    "\n",
    "splits = {\"train\": [], \"val\": [], \"test\": []}\n",
    "for label, items in by_label.items():\n",
    "    random.shuffle(items)\n",
    "    n = len(items)\n",
    "    n_val  = max(1, int(n * VAL_RATIO))\n",
    "    n_test = max(1, int(n * TEST_RATIO))\n",
    "    n_train = max(0, n - n_val - n_test)\n",
    "    splits[\"val\"].extend([(label, d, imgs) for d,imgs in items[:n_val]])\n",
    "    splits[\"test\"].extend([(label, d, imgs) for d,imgs in items[n_val:n_val+n_test]])\n",
    "    splits[\"train\"].extend([(label, d, imgs) for d,imgs in items[n_val+n_test:]])\n",
    "\n",
    "for d in (TRAIN_DIR, VAL_DIR, TEST_DIR):\n",
    "    if os.path.isdir(d):\n",
    "        shutil.rmtree(d)\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "    for cls in sorted(set(df_lbl[\"label\"])):\n",
    "        os.makedirs(os.path.join(d, cls), exist_ok=True)\n",
    "\n",
    "def safe_link(src, dst):\n",
    "    try:\n",
    "        os.symlink(src, dst)\n",
    "    except Exception:\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "def materialize(split_name):\n",
    "    cnt = 0\n",
    "    for label, dish, imgs in splits[split_name]:\n",
    "        for src in imgs:\n",
    "            dst = os.path.join(DATASET_ROOT, split_name, label, f\"{dish}__{Path(src).name}\")\n",
    "            if not os.path.exists(dst):\n",
    "                safe_link(src, dst)\n",
    "                cnt += 1\n",
    "    print(f\"{split_name}: wrote {cnt} image links/files.\")\n",
    "\n",
    "materialize(\"train\"); materialize(\"val\"); materialize(\"test\")\n",
    "print(\"✅ Splits ready:\")\n",
    "print(\"  train:\", sum(len(files) for _,_,files in splits[\"train\"]))\n",
    "print(\"  val  :\", sum(len(files) for _,_,files in splits[\"val\"]))\n",
    "print(\"  test :\", sum(len(files) for _,_,files in splits[\"test\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1d4db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 6) Train YOLO11n-cls on derived labels -----------------------------------\n",
    "# !pip install -U ultralytics\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import torch, ultralytics\n",
    "\n",
    "print(\"Ultralytics:\", ultralytics.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    import torch\n",
    "    print(\"Device:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "EPOCHS = 30   # Nutrition5k is large; start moderate, adjust as needed\n",
    "IMGSZ  = 224\n",
    "BATCH  = 64\n",
    "RUN_NAME = \"nutrition5k_yolo11n_cls_\" + (\"macro\" if \"macro\" in LABEL_STRATEGY else \"calbins\")\n",
    "\n",
    "model = YOLO(\"yolo11n-cls.pt\")\n",
    "results = model.train(\n",
    "    data=DATASET_ROOT,     # directory with train/val/test\n",
    "    epochs=EPOCHS,\n",
    "    imgsz=IMGSZ,\n",
    "    batch=BATCH,\n",
    "    lr0=1e-3,\n",
    "    patience=10,\n",
    "    project=MODEL_DIR,\n",
    "    name=RUN_NAME,\n",
    "    plots=True,\n",
    "    device=0 if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "print(\"Training run saved to:\", results.save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731c793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 7) Evaluate on val and test ----------------------------------------------\n",
    "from ultralytics import YOLO\n",
    "import glob, os, torch\n",
    "\n",
    "RUN_PREFIX = \"nutrition5k_yolo11n_cls_\"\n",
    "cands = glob.glob(os.path.join(MODEL_DIR, RUN_PREFIX + \"*\", \"weights\", \"best.pt\"))\n",
    "assert cands, f\"No best.pt found under {MODEL_DIR}/{RUN_PREFIX}*/weights/\"\n",
    "best_path = max(cands, key=os.path.getmtime)\n",
    "print(\"Using best:\", best_path)\n",
    "\n",
    "model = YOLO(best_path)\n",
    "\n",
    "metrics_val = model.val(\n",
    "    data=DATASET_ROOT,\n",
    "    split=\"val\",\n",
    "    imgsz=224,\n",
    "    project=MODEL_DIR,\n",
    "    name=RUN_PREFIX + \"val\",\n",
    "    device=0 if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "\n",
    "metrics_test = model.val(\n",
    "    data=DATASET_ROOT,\n",
    "    split=\"test\",\n",
    "    imgsz=224,\n",
    "    project=MODEL_DIR,\n",
    "    name=RUN_PREFIX + \"test\",\n",
    "    device=0 if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "print(\"Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
