{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "254399ae",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ“¦ `setup_datasets.ipynb` â€” clean runner\n",
    "This notebook **only calls helper functions** from your `util_dataset_helper_functions.py` so the notebook stays clean.\n",
    "It expects the following helpers (in your module) at minimum:\n",
    "\n",
    "- `read_datasets_json() -> (path, dict)`\n",
    "- `list_datasets(cfg: dict) -> list[str]`\n",
    "- `train_dataset_select(cfg: dict, name: str) -> dict`\n",
    "- `util_download_datasets(entry: dict) -> pathlib.Path`\n",
    "- (Optional) `prepare_dataset(entry: dict, raw_root: Path, prep_root: Path) -> dict`\n",
    "- (Or) for Food-101: `is_food101_root(path: Path) -> bool` and `prepare_food101_for_yolo_cls(...)`\n",
    "\n",
    "> Tip: If the import fails, adjust the **IMPORT PATHS** block below to match where your utils live (e.g. `./utilities/`).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "f6351f43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T09:12:39.577950Z",
     "start_time": "2025-10-30T09:12:39.571945Z"
    }
   },
   "source": [
    "\n",
    "# --- IMPORT PATHS (edit if needed) ---\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "CWD = Path.cwd()\n",
    "CANDIDATE_DIRS = [\n",
    "    CWD,\n",
    "    CWD / \"utilities\",\n",
    "    CWD / \"src\",\n",
    "]\n",
    "\n",
    "for p in CANDIDATE_DIRS:\n",
    "    sys.path.insert(0, str(p))\n",
    "\n",
    "# --- Import your utilities module ---\n",
    "try:\n",
    "    import util_dataset_helper_functions as uds\n",
    "except Exception as e_root:\n",
    "    try:\n",
    "        from utilities import util_dataset_helper_functions as uds\n",
    "    except Exception as e_sub:\n",
    "        raise ImportError(\n",
    "            \"Could not import 'util_dataset_helper_functions'. \"\n",
    "            \"Place it in project root or in ./utilities/ and re-run.\\n\"\n",
    "            f\"Errors:\\n - root import: {e_root}\\n - utilities import: {e_sub}\"\n",
    "        )\n",
    "\n",
    "# Sanity-print available attributes (helps verify versions)\n",
    "print(\"Loaded util module:\", uds.__file__)\n",
    "print(\"Available helpers:\", [n for n in dir(uds) if not n.startswith('_')][:25], \"...\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded util module: /home/kristoffel/utilities/util_dataset_helper_functions.py\n",
      "Available helpers: ['Any', 'DATASETS_DIR', 'DATASETS_JSON_CANDIDATES', 'Dict', 'HOME', 'Iterable', 'List', 'Optional', 'PREP_DIR', 'Path', 'Set', 'Tuple', 'annotations', 'detect_yolo_detection_layout', 'ensure_dir', 'is_food101_root', 'json', 'kagglehub', 'kagglehub_download', 'list_datasets', 'mirror_to_target', 'os', 'prepare_dataset', 'prepare_food101_for_yolo_cls', 'prepare_yolo_detection_passthrough'] ...\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "8199c154",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T09:12:43.014400Z",
     "start_time": "2025-10-30T09:12:43.010721Z"
    }
   },
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Dataset you want to prepare (must exist in datasets.json)\n",
    "SELECTED_DATASET = \"Food-101\"     # <-- change here if needed\n",
    "YOLO_READY_SUFFIX = \"-yolo\"       # output suffix\n",
    "DATASETS_DIR = Path(os.environ.get(\"IKT524_DATASETS_DIR\", Path.home() / \"datasets\")).expanduser()\n",
    "\n",
    "print(\"DATASETS_DIR:\", DATASETS_DIR)\n",
    "print(\"SELECTED_DATASET:\", SELECTED_DATASET)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASETS_DIR: /home/kristoffel/datasets\n",
      "SELECTED_DATASET: Food-101\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "c26cc2a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T09:12:45.719921Z",
     "start_time": "2025-10-30T09:12:45.698110Z"
    }
   },
   "source": [
    "\n",
    "# Expect read_datasets_json and list_datasets in your utils\n",
    "assert hasattr(uds, \"read_datasets_json\"), \"utils missing: read_datasets_json()\"\n",
    "assert hasattr(uds, \"list_datasets\"), \"utils missing: list_datasets(cfg)\"\n",
    "assert hasattr(uds, \"train_dataset_select\"), \"utils missing: train_dataset_select(cfg, name)\"\n",
    "\n",
    "cfg_path, cfg = uds.read_datasets_json()\n",
    "print(\"Loaded datasets.json from:\", cfg_path)\n",
    "print(\"Available datasets:\", uds.list_datasets(cfg))\n",
    "\n",
    "entry = uds.train_dataset_select(cfg, SELECTED_DATASET)\n",
    "print(\"Selected entry:\\n\", entry)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded datasets.json from: /home/kristoffel/datasets.json\n",
      "Available datasets: ['Nutrition5K', 'Food101', 'Food11', 'FooDD', 'iFood 2019 FGVC6', 'ISIA Food-500', 'Large-scale Food Recognition', 'Food-Ingredient-Dataset-51', 'UECFoodPix & UECFoodPixComplete']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Dataset named 'Food-101' not found in datasets.json\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoaded datasets.json from:\u001B[39m\u001B[38;5;124m\"\u001B[39m, cfg_path)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAvailable datasets:\u001B[39m\u001B[38;5;124m\"\u001B[39m, uds\u001B[38;5;241m.\u001B[39mlist_datasets(cfg))\n\u001B[0;32m---> 10\u001B[0m entry \u001B[38;5;241m=\u001B[39m \u001B[43muds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_dataset_select\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mSELECTED_DATASET\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSelected entry:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, entry)\n",
      "File \u001B[0;32m~/utilities/util_dataset_helper_functions.py:150\u001B[0m, in \u001B[0;36mtrain_dataset_select\u001B[0;34m(cfg, name)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m d\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m==\u001B[39m name:\n\u001B[1;32m    149\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m d\n\u001B[0;32m--> 150\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset named \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m not found in datasets.json\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"Dataset named 'Food-101' not found in datasets.json\""
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "b7d30b0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T17:42:17.607509Z",
     "start_time": "2025-10-27T17:42:17.592591Z"
    }
   },
   "source": [
    "\n",
    "assert hasattr(uds, \"util_download_datasets\"), \"utils missing: util_download_datasets(entry)\"\n",
    "raw_root = uds.util_download_datasets(entry)\n",
    "print(\"Raw dataset root:\", raw_root)\n",
    "\n",
    "prep_root = DATASETS_DIR / f\"{SELECTED_DATASET}{YOLO_READY_SUFFIX}\"\n",
    "print(\"Prepared output folder will be:\", prep_root)\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'entry' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(uds, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutil_download_datasets\u001B[39m\u001B[38;5;124m\"\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutils missing: util_download_datasets(entry)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 2\u001B[0m raw_root \u001B[38;5;241m=\u001B[39m uds\u001B[38;5;241m.\u001B[39mutil_download_datasets(\u001B[43mentry\u001B[49m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRaw dataset root:\u001B[39m\u001B[38;5;124m\"\u001B[39m, raw_root)\n\u001B[1;32m      5\u001B[0m prep_root \u001B[38;5;241m=\u001B[39m DATASETS_DIR \u001B[38;5;241m/\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mSELECTED_DATASET\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mYOLO_READY_SUFFIX\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'entry' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "be580fe3",
   "metadata": {},
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "summary = None\n",
    "\n",
    "# Preferred generic API if your utils provide it\n",
    "if hasattr(uds, \"prepare_dataset\"):\n",
    "    summary = uds.prepare_dataset(entry, Path(raw_root), Path(prep_root))\n",
    "\n",
    "else:\n",
    "    # Food-101 specific fallback (kept minimal)\n",
    "    fmt = entry.get(\"format\", \"\").lower()\n",
    "    if fmt == \"food101\" or (hasattr(uds, \"is_food101_root\") and uds.is_food101_root(Path(raw_root))):\n",
    "        assert hasattr(uds, \"prepare_food101_for_yolo_cls\"), \\\n",
    "            \"utils missing: prepare_food101_for_yolo_cls(food101_root, out_root)\"\n",
    "        summary = uds.prepare_food101_for_yolo_cls(Path(raw_root), Path(prep_root))\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            \"No generic prepare_dataset() provided and dataset format is not Food-101.\\n\"\n",
    "            \"Add a handler to utils (e.g., prepare_<format>...) and expose it via prepare_dataset().\"\n",
    "        )\n",
    "\n",
    "print(\"\\\\n=== SUMMARY ===\")\n",
    "if isinstance(summary, dict):\n",
    "    for k, v in summary.items():\n",
    "        if isinstance(v, list):\n",
    "            print(f\"{k}: {len(v)} items\")\n",
    "        else:\n",
    "            print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(summary)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "afc8e63c",
   "metadata": {},
   "source": [
    "\n",
    "## âœ… Next steps\n",
    "- Train (Ultralytics classification example):\n",
    "  ```bash\n",
    "  yolo task=classify mode=train model=yolo11n-cls.pt data=\"<path to prepared folder or YAML>\"\n",
    "  ```\n",
    "\n",
    "- Switch `SELECTED_DATASET` at the top to prepare a different dataset defined in `datasets.json`.\n",
    "\n",
    "- If you add new dataset formats, expose a single entry point `prepare_dataset(entry, raw_root, prep_root)` in your utils.  \n",
    "  This notebook will pick it up automatically and stay clean.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
